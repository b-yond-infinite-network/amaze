{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1398468b",
   "metadata": {},
   "source": [
    "# Evil Net - Streamming Example\n",
    "\n",
    "\n",
    "\n",
    "The intention of the Notebook is showcase how to:\n",
    "\n",
    "1. Instantiate Spark to \n",
    "    1. Connect Spark to Kafka\n",
    "1. Create and Streaming Context\n",
    "1. Parser Data Fetched from Kafka\n",
    "1. Produce a Sample Count for The key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a94ee6",
   "metadata": {},
   "source": [
    "## In Addtion The following function will be use\n",
    "### updateStateByKey\n",
    "The `updateStateByKey` operation allows you to maintain arbitrary state while continuously updating it with new information. To use this, you will have to do two steps.\n",
    "1. Define the state - The state can be an arbitrary data type.\n",
    "2. Define the state update function - Specify with a function how to update the state using the previous state and the new values from an input stream.\n",
    "In every batch, Spark will apply the state update function for all existing keys, regardless of whether they have new data in a batch or not. If the update function returns None then the key-value pair will be eliminated.\n",
    "\n",
    "Let’s illustrate this with an example. Say you want to maintain a running count of each word seen in a text data stream. Here, the running count is the state and it is an integer. We define the update function as:\n",
    "```python\n",
    "def updateFunction(newValues, runningCount):\n",
    "    if runningCount is None:\n",
    "        runningCount = 0\n",
    "    return sum(newValues, runningCount)  # add the new values with the previous running count to get the new count\n",
    "```\n",
    "This is applied on a DStream containing words (say, the `pairs` DStream containing `(word, 1)` pairs in the earlier [example](https://spark.apache.org/docs/latest/streaming-programming-guide.html#a-quick-example)).\n",
    "```python\n",
    "runningCounts = pairs.updateStateByKey(updateFunction)\n",
    "```\n",
    "The update function will be called for each word, with `newValues` having a sequence of 1’s (from the (word, 1) pairs) and the `runningCount` having the previous count. For the complete Python code, take a look at the example [stateful_network_wordcount.py](https://github.com/apache/spark/blob/v2.2.0/examples/src/main/python/streaming/stateful_network_wordcount.py).\n",
    "\n",
    "Note that using `updateStateByKey` requires the checkpoint directory to be configured, which is discussed in detail in the [checkpointing](https://spark.apache.org/docs/latest/streaming-programming-guide.html#checkpointing) section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fac7565",
   "metadata": {},
   "source": [
    "#  Libs Version Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36220045",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T19:52:51.854630Z",
     "start_time": "2021-05-14T19:52:51.530180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############## Versioning ##############\n",
      "----------- IPython: 7.23.1 ------------\n",
      "------------ PySpark: 2.4.7 ------------\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "from IPython import __version__ as ipython_version\n",
    "from pyspark import __version__ as pyspark_version\n",
    "\n",
    "VERSION = \" Versioning \"\n",
    "IPYTHON = \" IPython: %s \" % ipython_version\n",
    "PYSPARK = \" PySpark: %s \" % pyspark_version\n",
    "\n",
    "print(VERSION.center(40, '#'))\n",
    "print(IPYTHON.center(40, \"-\"))\n",
    "print(PYSPARK.center(40, \"-\"))\n",
    "print(\"\".center(40, '#'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd32be9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T19:28:07.502497Z",
     "start_time": "2021-05-14T19:28:07.492156Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Import Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb5b52f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T19:52:52.450377Z",
     "start_time": "2021-05-14T19:52:52.423894Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from json import loads as js_loads\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69d4e84",
   "metadata": {},
   "source": [
    "# Create a Spark Conf \n",
    "\n",
    "## Adding the Kafka Package\n",
    "## Set Master-Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "769d09be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T19:54:19.674884Z",
     "start_time": "2021-05-14T19:52:53.075845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://a59658eb2cf1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>JupyterSpark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://spark-master:7077 appName=JupyterSpark>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_conf = (SparkConf().set(\n",
    "    \"spark.jars.packages\",\n",
    "    \"org.apache.spark:spark-streaming-kafka-0-8_2.11:2.0.2\").setMaster(\n",
    "        \"spark://spark-master:7077\").setAppName(\"JupyterSpark\"))\n",
    "spark_context = SparkContext.getOrCreate(spark_conf)\n",
    "spark_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e1e09d",
   "metadata": {},
   "source": [
    "### Create Streaming Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "230c5673",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T19:54:22.060667Z",
     "start_time": "2021-05-14T19:54:19.681505Z"
    }
   },
   "outputs": [],
   "source": [
    "ssc = StreamingContext(spark_context, 1)\n",
    "brokers, topics = 'localhost:9092', ['stream-tweets']\n",
    "kvs = KafkaUtils.createDirectStream(\n",
    "    ssc, topics, {\n",
    "        'bootstrap.servers': 'by-kafka-broker:9092',\n",
    "        'group.id': 'video-group',\n",
    "        'auto.offset.reset': 'smallest'\n",
    "    })\n",
    "ssc.checkpoint(\"./checkpoint-tweet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62683bbe",
   "metadata": {},
   "source": [
    "## Supportin Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f625086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T19:54:22.086528Z",
     "start_time": "2021-05-14T19:54:22.067875Z"
    }
   },
   "outputs": [],
   "source": [
    "def shrink(x):\n",
    "    \"\"\"Just get the data.lang\"\"\"\n",
    "    return x[\"data\"].get(\"lang\", \"unknown\")\n",
    "\n",
    "\n",
    "def state_full_sum(new_values, global_sum):\n",
    "    return sum(new_values) + (global_sum or 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b4854e",
   "metadata": {},
   "source": [
    "### Kafka Data:\n",
    "Kafka is a Key-value, our Evil net only focus on values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f63ace7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T19:54:22.140457Z",
     "start_time": "2021-05-14T19:54:22.112668Z"
    }
   },
   "outputs": [],
   "source": [
    "lines = kvs.map(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9582e4b0",
   "metadata": {},
   "source": [
    "## Tranform Data over Windows of 20 sec over slide of 4 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e982e56b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T19:54:22.399936Z",
     "start_time": "2021-05-14T19:54:22.170325Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "langs_count = lines.window(windowDuration=20, slideDuration=4).map(\n",
    "    js_loads).map(shrink).map(lambda word: (word, 1)).updateStateByKey(\n",
    "        state_full_sum)\n",
    "langs_count.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eca330",
   "metadata": {},
   "source": [
    "# Start the Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7b65913",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T19:54:23.116141Z",
     "start_time": "2021-05-14T19:54:22.405275Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2021-05-14 19:54:26\n",
      "-------------------------------------------\n",
      "('en', 72)\n",
      "('und', 4)\n",
      "('tl', 1)\n",
      "('ar', 1)\n",
      "('ja', 1)\n",
      "('es', 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2021-05-14 19:54:30\n",
      "-------------------------------------------\n",
      "('en', 145)\n",
      "('und', 8)\n",
      "('tl', 2)\n",
      "('ar', 2)\n",
      "('ja', 3)\n",
      "('es', 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cccb84",
   "metadata": {},
   "source": [
    "# Stop Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dbe9dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T19:35:10.081718Z",
     "start_time": "2021-05-14T19:34:55.341774Z"
    }
   },
   "outputs": [],
   "source": [
    "ssc.stop(stopSparkContext=True,stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cff9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "381px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
